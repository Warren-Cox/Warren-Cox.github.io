[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Warren Cox. I am GIS masters student studying at UTD after earning a BS in GIS also from UTD. I am passionate about GIS and the applications it has in every field. You will find my resume and CV below which provide more detail to my credentials.\n\n\n\n\n\n\n\nCV:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resume.html#student-at-the-university-of-texas-at-dallas",
    "href": "resume.html#student-at-the-university-of-texas-at-dallas",
    "title": "About Me",
    "section": "",
    "text": "My name is Warren Cox. I am GIS masters student studying at UTD after earning a BS in GIS also from UTD. I am passionate about GIS and the applications it has in every field. You will find my resume and CV below which provide more detail to my credentials.\n\n\n\n\n\n\n\nCV:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Website",
    "section": "",
    "text": "Welcome to my Website!"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "EPPS 6356",
    "section": "",
    "text": "Generative art by Katharina Brunner\n\n\n\n\n\nFor the file Fall.R click here\n\n\n\nThe following is an example of a graphic found in the article Mapping the Political Landscape: Toward a GIS Analysis of Environmental and Social Difference\n\n\n\n\n\nThe graphic shows the location of buildings and terraces over space, with some specific location labels to add more data. The biggest hindrance to the success of this graphic is the limited use of color, font and texture. It is not easy to distinguish between pieces of information in the graphic since it is largely just dependent on line thickness. Black font on top of multiple types of black elements, over a grey scale background ultimately make a cluttered and confusing display that seems overly compacted. The strict border imposed on the graphic makes it well contain but also contributes to this feeling. The location identifiers around the map are both repeated and not necessary for the information displayed. An inset map could be employed instead as a separate graphic. The text over the graphic adds limited value as well. They are meant to represent building type areas, but without any boundaries visible or a link to specific buildings, they add almost no novel data."
  },
  {
    "objectID": "assignments.html#assignment-1-9112024",
    "href": "assignments.html#assignment-1-9112024",
    "title": "EPPS 6356",
    "section": "",
    "text": "Generative art by Katharina Brunner\n\n\n\n\n\nFor the file Fall.R click here\n\n\n\nThe following is an example of a graphic found in the article Mapping the Political Landscape: Toward a GIS Analysis of Environmental and Social Difference\n\n\n\n\n\nThe graphic shows the location of buildings and terraces over space, with some specific location labels to add more data. The biggest hindrance to the success of this graphic is the limited use of color, font and texture. It is not easy to distinguish between pieces of information in the graphic since it is largely just dependent on line thickness. Black font on top of multiple types of black elements, over a grey scale background ultimately make a cluttered and confusing display that seems overly compacted. The strict border imposed on the graphic makes it well contain but also contributes to this feeling. The location identifiers around the map are both repeated and not necessary for the information displayed. An inset map could be employed instead as a separate graphic. The text over the graphic adds limited value as well. They are meant to represent building type areas, but without any boundaries visible or a link to specific buildings, they add almost no novel data."
  },
  {
    "objectID": "assignments.html#assignment-2-9252024",
    "href": "assignments.html#assignment-2-9252024",
    "title": "EPPS 6356",
    "section": "Assignment 2 (9/25/2024)",
    "text": "Assignment 2 (9/25/2024)\nUsing Murrell’s Functions on HPI Data\n\n\nNew names:\n• `` -&gt; `...4`\n\n\n\n\n\n\n\n\n\n\nPage About Big Data Pitfalls\nIn the modern digital age, the increasing availability of large datasets, commonly referred to as “big data,” has revolutionized the way organizations, governments, and researchers analyze information. Big data holds enormous potential to uncover trends, inform decision-making, and improve predictive models across a wide array of fields. However, despite these advantages, the use of big data also presents significant risks, particularly when it comes to overfitting and overparameterization. If left unchecked, these issues can lead to inaccurate predictions, misguided conclusions, and the erosion of public trust in data-driven models. The case of Google Flu Trends serves as a cautionary tale, highlighting the dangers of relying too heavily on big data without sufficient consideration of its limitations. Overfitting occurs when a model is excessively complex and begins to capture not only the underlying patterns in the data but also the noise and random fluctuations present in the dataset. In other words, an overfit model is tailored too closely to the training data, which compromises its ability to generalize to new, unseen data. This problem is particularly common in big data environments, where the sheer volume of information can lead to the development of highly intricate models. While such models may perform exceptionally well on historical datasets, they often fail to provide accurate predictions when applied to new or evolving situations. Overparameterization, a closely related issue, occurs when a model incorporates an excessive number of parameters relative to the amount of useful information in the data. It can result from throwing variables at a problem and seeing what sticks, rather than stopping and asking why. This leads to a situation where the model becomes overly sensitive to minor changes or irrelevant features in the dataset. In the context of big data, the abundance of variables available for analysis may tempt researchers to create models with a vast number of parameters, especially if they seemingly predict trends. However, doing so increases the risk of producing a model that lacks robustness and overfits the data. The more parameters a model has, the more likely it is to describe spurious correlations that do not reflect true underlying relationships. Additionally, it is important to know that while large, big data is not the result of the entire population. It falls susceptible to sampling error and bias. If this factor is ignored the model runs the risk of only working on similar datasets, especially those it was trained on. Bigger is not always better and well implemented samples remain statistically more significant than big data analytics. Big data promises a model, however, that is cheaper and easier to produce and update than traditional methods. These benefits must be weighed against the potential issues in sampling, misrepresentation, and loss of logical reasoning. Google Flu Trends fell victim to these mishaps in big data use. The model relied heavily on a wide range of search terms, which regularly were updated, many of which turned out to be unrelated or only tangentially associated with flu activity. As the model grew more complex, it became increasingly sensitive to shifts in search behavior that did not correspond to real-world flu cases. Moreover, the data it relied on was not static—human behavior, particularly online search behavior, evolves over time. IT was also susceptible to googles own search algorithm suggestions, which manipulated users search frequencies. This evolution rendered GFT’s predictions increasingly unreliable as the model struggled to adapt to new patterns in the data. The Google Flu debacle highlights the importance of maintaining a balanced approach to big data analysis. While big data offers powerful opportunities to uncover patterns and make predictions, it is crucial that researchers and data scientists remain mindful of the risks posed by misusing statistics. Models must be kept as simple as possible while still capturing meaningful patterns. Cross-validation techniques should be employed to test the model’s performance on new data, ensuring that it is not overly tailored to the idiosyncrasies of the training set. Furthermore, integrating domain knowledge into the modeling process can help to ensure that the parameters used are grounded in reality rather than being driven by data alone. In conclusion, big data, when used properly, has the potential to drive significant advancements in predictive analytics and decision-making. However, it also presents considerable dangers, especially when complex models are allowed to overfit or become overparameterized. The Google Flu Trends case provides a clear illustration of how these issues can arise, even in high-profile projects. As data continues to grow in volume and variety, it is imperative that researchers adopt rigorous practices to ensure that their models remain accurate, reliable, and ageneralization to real-world scenarios.\n\n\nResponse to Wickham Video\nWickham showcases they R packages that make up the tidy verse. He focuses especially on the package ggplot2 the premier R graphic maker. This package builds of the conceptual ideas from the Grammar of Graphics which is a book providing the fundamental components of digital graphic creation. R is the practical implementation of the concepts discussed in this book and allows users to programmatically create graphics built of graphical components. He focuses on this package and the reason a programing approach is ideal for graphic creation. He stresses the ease of explanation and reproduction that comes with programing graphics."
  },
  {
    "objectID": "lab4.html",
    "href": "lab4.html",
    "title": "lab4",
    "section": "",
    "text": "knitr::opts_chunk$set(warning = FALSE)"
  },
  {
    "objectID": "lab4.html#chart-1-by-mamie-cincotta",
    "href": "lab4.html#chart-1-by-mamie-cincotta",
    "title": "lab4",
    "section": "Chart 1 by Mamie Cincotta",
    "text": "Chart 1 by Mamie Cincotta\nThis graphic is a bar plot depicting the carbon footprint of different regions around the world, with each bar’s width proportional to the population size of the corresponding region. The y-axis represents the total carbon footprint in metric tons of CO₂ equivalent (tCO₂e) for each region, while the x-axis lists the regions, including South America, North America & Oceania, Western Europe, and others. The names of the regions are displayed at an angle for readability (due to las = 2), and the bar widths are scaled based on the population size for each region, emphasizing the relative population contribution to the region’s carbon footprint. The color of the bars is set to “steelblue,” and the overall title of the plot is “Carbon Footprint by Region with Population Widths,” illustrating the relationship between population and carbon emissions across different global regions.\n\n# Aggregate data\ncontems &lt;- aggregate(happyplanetdf$\"Carbon Footprint (tCO2e)\", list(happyplanetdf$Continent), FUN = sum)\ncontpop &lt;- aggregate(happyplanetdf$\"Population (thousands)\", list(happyplanetdf$Continent), FUN = sum)\n \n# Name the regions\nnames &lt;- c(\"South America\", \"North America and Oceania\",\"Western Europe\",\"Middle East\", \"Africa\", \"South Asia\", \"Eastern Europe & Central Asia\", \"East Asia\")\ndata &lt;- data.frame(contems, names)\n \n# Make the plot\nbarplot(width = contpop$x, height = contems$x, names=rep(data$names), las = 2, cex.names=.5, ylab = \"Carbon Footprint\", xlab = \"Region\", main = \"Carbon Footprint by Region with Population Widths\", col = \"steelblue\")"
  },
  {
    "objectID": "lab4.html#chart-2-by-warren-cox",
    "href": "lab4.html#chart-2-by-warren-cox",
    "title": "lab4",
    "section": "Chart 2 by Warren Cox",
    "text": "Chart 2 by Warren Cox\nThis code generates a scatterplot matrix for key variables in the Happy Planet Index (HPI) dataset, providing a visual representation of the relationships between six different variables: Population, Life Expectancy, Wellbeing (Ladder of Life), Carbon Footprint, HPI, and GDP per capita. The matrix includes pairwise scatterplots that help identify potential correlations between variables.\nThis matrix helps identify potential trends, correlations, and distributions in the HPI data. It can reveal patterns such as whether regions with higher GDP per capita also have higher well-being or lower carbon footprints, and allows users to explore multivariate relationships between the key HPI indicators.\n\nselected_data &lt;- happyplanetdf[c(\"Population (thousands)\",\"Life Expectancy (years)\",\"Ladder of life (Wellbeing) (0-10)\",\"Carbon Footprint (tCO2e)\",\"HPI\",\"GDP per capita ($)\", \"Continent\")]\n \npar(family = \"serif\", cex = 1.5) \nlibrary(psych)\npairs.panels(selected_data[1:6],\n             main = \"Scatterplot Matrix of HPI Data Variables\",\n             method = \"pearson\", # correlation method\n             hist.col = \"forestgreen\",\n             density = TRUE,  # show density plots\n             ellipses = FALSE)"
  },
  {
    "objectID": "lab4.html#chart-3-by-liberty-smith",
    "href": "lab4.html#chart-3-by-liberty-smith",
    "title": "lab4",
    "section": "Chart 3 by Liberty Smith",
    "text": "Chart 3 by Liberty Smith\nThis horizontal stacked bar chart visualizes the distribution of countries by Wellbeing Category across various continents. The x-axis represents the number of countries in each continent, while the y-axis lists the continents, including Latin America, North America & Oceania, Western Europe, and others. Each bar is stacked by Wellbeing Category (Good, Average, Poor), with different colors indicating the categories: seagreen for “Good,” goldenrod for “Average,” and firebrick for “Poor.” The chart allows for easy comparison of how countries within each continent are distributed across these wellbeing categories, with the custom labels improving readability. The use of coord_flip() makes the bars horizontal, providing a clear and concise visual representation of the data.\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following objects are masked from 'package:psych':\n\n    %+%, alpha\n\nlibrary(tidyr)\n\n# Categorize Life Expectancy, Wellbeing, and Carbon Footprint\nhappyplanetdf &lt;- happyplanetdf %&gt;%\n  \n  # Categorize Wellbeing\n  mutate(Wellbeing_Category = case_when(\n    `Ladder of life (Wellbeing) (0-10)` &lt; 5.0 ~ \"Poor\",\n    `Ladder of life (Wellbeing) (0-10)` &gt;= 5.1 & `Ladder of life (Wellbeing) (0-10)` &lt; 6.0 ~ \"Average\",\n    `Ladder of life (Wellbeing) (0-10)` &gt;= 6.0 ~ \"Good\",\n    TRUE ~ NA_character_  # For missing values, set NA\n  ))\n# Remove NA values in Wellbeing_Category for this plot\nclean_data &lt;- happyplanetdf %&gt;%\n  filter(!is.na(Wellbeing_Category))\n\n# Count the number of countries per continent and wellbeing category\ncount_data &lt;- clean_data %&gt;%\n  group_by(Continent, Wellbeing_Category) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Continent'. You can override using the\n`.groups` argument.\n\n# Custom continent labels\ncontinent_labels &lt;- c(\n  \"1\" = \"Latin\\nAmerica\",\n  \"2\" = \"N. America\\n& Oceania\",\n  \"3\" = \"Western\\nEurope\",\n  \"4\" = \"Middle\\nEast\",\n  \"5\" = \"Africa\",\n  \"6\" = \"South\\nAsia\",\n  \"7\" = \"Eastern Europe\\n& Central Asia\",\n  \"8\" = \"East\\nAsia\"\n)\n\n# Create the horizontal stacked bar chart\nggplot(count_data, aes(x = Continent, y = Count, fill = Wellbeing_Category)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_discrete(labels = continent_labels) +  # Apply custom labels\n  labs(title = \"Number of Countries per Continent by Wellbeing Category\",\n       x = \"Continent\", y = \"Number of Countries\", fill = \"Wellbeing Category\") +\n  scale_fill_manual(values = c(\"Good\" = \"seagreen\", \"Average\" = \"goldenrod\", \"Poor\" = \"firebrick\")) +\n  theme_minimal() +\n  coord_flip()  # This flips the chart horizontally"
  },
  {
    "objectID": "lab4.html#chart-4-by-shiu-ting-ling",
    "href": "lab4.html#chart-4-by-shiu-ting-ling",
    "title": "lab4",
    "section": "Chart 4 By Shiu-Ting Ling",
    "text": "Chart 4 By Shiu-Ting Ling\nThis bar chart depicts the number of countries in each continent that have an HPI (Happy Planet Index) above or below the global average. The x-axis represents continents, with custom labels such as “Latin America,” “Western Europe,” and “East Asia.” The y-axis represents the number of countries in each continent. The chart differentiates between countries with higher HPI (colored in firebrick2) and those with lower HPI (colored in dodgerblue2), using side-by-side bars for each continent to indicate the count. The custom labels in the legend clarify the categories: “Countries with higher HPI” and “Countries with lower HPI.” The chart’s title, “Number of Countries Above/Below Average HPI by Continent,” succinctly summarizes the data. The labels on the x-axis are kept horizontal for readability, and the minimalist theme ensures the focus remains on the data while small adjustments like legend size and text formatting improve the overall presentation.\n\n# Calculate the average HPI for all countries\naverage_hpi &lt;- mean(happyplanetdf$HPI, na.rm = TRUE)\n\n# Define custom continent names\ncontinent_names &lt;- c(\"Africa\", \n                     \"Latin\\nAmerica\", \n                     \"North\\nAmerica\\n&\\nOceania\", \n                     \"Eastern\\nEurope\\n&\\nCentral\\nAsia\", \n                     \"East\\nAsia\", \n                     \"Middle\\nEast\\n&\\nNorth\\nAfrica\", \n                     \"South\\nAsia\", \n                     \"Western\\nEurope\")\n\n# Update the Continent column as a factor and assign custom labels\nhappyplanetdf$Continent &lt;- factor(happyplanetdf$Continent, \n                                  levels = 1:8, \n                                  labels = continent_names)\n\n# Calculate the number of countries in each continent above and below the average HPI\ncontinent_hpi_comparison &lt;- happyplanetdf %&gt;%\n    group_by(Continent) %&gt;%\n    summarise(\n        High_HPI_Count = sum(HPI &gt; average_hpi, na.rm = TRUE),\n        Low_HPI_Count = sum(HPI &lt;= average_hpi, na.rm = TRUE)\n    ) %&gt;%\n    pivot_longer(cols = c(\"High_HPI_Count\", \"Low_HPI_Count\"), names_to = \"HPI_Category\", values_to = \"Country_Count\")\n\n# Use ggplot2 to create a bar chart and adjust the angle of x-axis labels\nggplot(continent_hpi_comparison, aes(x = Continent, y = Country_Count, fill = HPI_Category)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(title = \"Number of Countries Above/Below Average HPI by Continent\",\n         x = \"Continent\",\n         y = \"Number of Countries\",\n         fill = \"HPI Category\") +\n    scale_fill_manual(\n        values = c(\"High_HPI_Count\" = \"firebrick2\", \"Low_HPI_Count\" = \"dodgerblue2\"),  # Optional: Define custom colors for each category\n        labels = c(\"High_HPI_Count\" = \"Countries with\\nhigher HPI\", \n                   \"Low_HPI_Count\" = \"Countries with\\nlower HPI\")  # Change legend labels\n    ) +\n    theme_minimal() +\n    theme(\n        legend.position = \"right\",                  # Set legend position to the right\n        legend.key.size = unit(0.5, \"cm\"),           # Make the legend boxes smaller\n        legend.text = element_text(size = 6),        # Change the legend text size\n        axis.text.x = element_text(size = 8,         # Adjust x-axis label text size\n                                   angle = 0,        # Keep x-axis labels horizontal\n                                   hjust = 0.5,        # Adjust horizontal alignment\n                                   vjust = 0.5,),      # Adjust vertical alignment\n        plot.title = element_text(size = 12,         # Increase the title font size\n                                  face = \"bold\",     # Set title to bold\n                                  margin = margin(t = 10, b = 10))  # Add margin to title for spacing\n    )"
  },
  {
    "objectID": "assignments.html#assignment-4-1042024",
    "href": "assignments.html#assignment-4-1042024",
    "title": "EPPS 6356",
    "section": "Assignment 4 (10/4/2024)",
    "text": "Assignment 4 (10/4/2024)"
  }
]